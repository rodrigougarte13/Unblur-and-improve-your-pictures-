{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33ef319-368a-4dbe-9cda-80a1274305df",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac87b62-54e8-4690-be34-c8c697abd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebabd42-7df9-4c46-9d86-dc24e343b9dd",
   "metadata": {},
   "source": [
    "## Blur, darken and augment photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1799c804-8b0d-49a8-ad45-b9c52c297769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_blur(image): # blur the images\n",
    "    ksize = np.random.choice(range(5, 35, 2))\n",
    "    image = cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "    return image\n",
    "\n",
    "def random_darken(image): # darken the images\n",
    "    factor = np.random.uniform(0.3, 0.7)\n",
    "    image = np.clip(image * factor, 0, 255).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def distort_image(image): # Randomly decide to blur or darken\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = random_blur(image)\n",
    "    else:\n",
    "        image = random_darken(image)\n",
    "    return image\n",
    "    \n",
    "def random_augmentation(image): # augment the dataset with flips, rotation and contrast adjust for improving our results\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f82f63-117e-4635-a356-6bf7ff61fa6e",
   "metadata": {},
   "source": [
    "### Test if the functions are producing the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57fd134f-4f82-4436-b643-98930b7af02c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m blurred_image \u001b[38;5;241m=\u001b[39m random_blur(image)\n\u001b[0;32m      3\u001b[0m darkened_image \u001b[38;5;241m=\u001b[39m random_darken(image)\n\u001b[0;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblurred_test.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, blurred_image)\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mrandom_blur\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_blur\u001b[39m(image): \u001b[38;5;66;03m# blur the images\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     ksize \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(image, (ksize, ksize), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "blurred_image = random_blur(image)\n",
    "darkened_image = random_darken(image)\n",
    "\n",
    "cv2.imwrite('blurred_test.jpg', blurred_image)\n",
    "cv2.imwrite('darkened_test.jpg', darkened_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0bd8bd-6cc5-4979-83ba-a09a532ed837",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3b73441-aefa-40b9-919e-95275c443550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path):\n",
    "    image_path = image_path.numpy().decode('utf-8')\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # distortions\n",
    "    distorted_image = distort_image(original_image.copy())\n",
    "\n",
    "    # resize to 256x256\n",
    "    original_image = cv2.resize(original_image, (256, 256))\n",
    "    distorted_image = cv2.resize(distorted_image, (256, 256))\n",
    "\n",
    "    # normalize\n",
    "    original_image = original_image / 255.0\n",
    "    distorted_image = distorted_image / 255.0\n",
    "\n",
    "    return distorted_image.astype(np.float32), original_image.astype(np.float32)\n",
    "\n",
    "def tf_process_path(image_path):\n",
    "    distorted_image, original_image = tf.py_function(process_path, [image_path], [tf.float32, tf.float32])\n",
    "    distorted_image.set_shape([256, 256, 3])\n",
    "    original_image.set_shape([256, 256, 3])\n",
    "    return distorted_image, original_image\n",
    "\n",
    "def load_dataset(image_dir, batch_size=16):\n",
    "    image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir)]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    dataset = dataset.map(tf_process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths) * 2)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset   \n",
    "\n",
    "train_dir = 'train_test'\n",
    "validation_dir = 'val_test'\n",
    "\n",
    "train_dataset = load_dataset(train_dir, batch_size=16)\n",
    "validation_dataset = load_dataset(validation_dir, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0ecc864-9e37-4bab-a6f9-735353cdf9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830df148-1843-40bc-b3da-dbce8daff7e1",
   "metadata": {},
   "source": [
    "# UNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "137c2cc9-9720-409b-8d98-77790badbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0efd58f-f367-4d78-8d7e-5f4e42be4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # decoder\n",
    "    up6 = Concatenate()([UpSampling2D(size=(2, 2))(conv5), conv4])\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Concatenate()([UpSampling2D(size=(2, 2))(conv6), conv3])\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Concatenate()([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Concatenate()([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = Conv2D(3, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model\n",
    "    \n",
    "checkpoint_path = \"../models/checkpoint_unet_model.keras\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23393c-43e2-4892-9257-39a93920b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=50, batch_size=16, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d85b5c-d0ae-4ad2-8179-3ab9fa92c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88321b0e-ab2c-418b-b278-e28026084650",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(validation_generator)\n",
    "print(f\"Validation Loss: {evaluation[0]}\")\n",
    "print(f\"Validation Accuracy: {evaluation[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab4197-78ef-4cd0-a9a9-baa8d8e4898a",
   "metadata": {},
   "source": [
    "## TESTING HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ed604-2e66-43a1-a020-101ddcbf50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/unet_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf6ab9-21c4-4f0b-863f-b78cfb4119b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(''../models/unet_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd2f05-96a3-4827-8520-b4639ad52ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = cv2.imread('path/to/test/image.jpg')\n",
    "test_image = cv2.resize(test_image, (256, 256))  # Resize to the input size of the model\n",
    "test_image = test_image / 255.0  # Normalize if necessary\n",
    "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict the restored image\n",
    "restored_image = model.predict(test_image)\n",
    "\n",
    "# Postprocess and display the restored image\n",
    "restored_image = np.squeeze(restored_image)  # Remove batch dimension\n",
    "restored_image = restored_image * 255.0  # Denormalize if necessary\n",
    "restored_image = restored_image.astype(np.uint8)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Restored Image', restored_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
